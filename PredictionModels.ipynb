{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2rHrKG66NW8UUHO9gnBoM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nourk1/eCornellfolder/blob/main/PredictionModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# Load and preprocess the data\n",
        "def load_and_merge_data(donations_file, demographics_file, zipcode_file):\n",
        "    # Load data\n",
        "    donations_df = pd.read_csv(donations_file)\n",
        "    demographics_df = pd.read_csv(demographics_file)\n",
        "    zipcode_df = pd.read_csv(zipcode_file)\n",
        "\n",
        "    # Convert date column to datetime\n",
        "    donations_df['Close Date'] = pd.to_datetime(donations_df['Close Date'])\n",
        "\n",
        "    # Rename columns for consistency\n",
        "    donations_df.rename(columns={'Billing Zip/Postal Code': 'Billing_Zipcode'}, inplace=True)\n",
        "    zipcode_df.rename(columns={'zip_code': 'Zip_Code', 'zcta': 'ZCTA'}, inplace=True)\n",
        "\n",
        "    # Ensure ZIP codes are strings\n",
        "    donations_df['Billing_Zipcode'] = donations_df['Billing_Zipcode'].astype(str)\n",
        "    zipcode_df['Zip_Code'] = zipcode_df['Zip_Code'].astype(str)\n",
        "\n",
        "    # Merge datasets\n",
        "    donations_merged = donations_df.merge(zipcode_df, left_on='Billing_Zipcode', right_on='Zip_Code', how='left')\n",
        "    donations_merged = donations_merged.merge(demographics_df, on='ZCTA', how='left')\n",
        "\n",
        "    return donations_merged, demographics_df\n",
        "\n",
        "# Create labels for donors\n",
        "def create_labels(donations_merged, model_date):\n",
        "    model_date = pd.to_datetime(model_date)\n",
        "    training_donors = donations_merged[donations_merged['Close Date'] < model_date]['Masked Account ID'].unique()\n",
        "    evaluation_donors = donations_merged[\n",
        "        (donations_merged['Close Date'] >= model_date) &\n",
        "        (donations_merged['Close Date'] < f'{model_date.year + 1}-01-01')\n",
        "    ]['Masked Account ID'].unique()\n",
        "    return training_donors, evaluation_donors\n",
        "\n",
        "# Gather features for a donor\n",
        "def gather_features(donor_id, donations_merged, selected_features):\n",
        "    donor_data = donations_merged[donations_merged['Masked Account ID'] == donor_id]\n",
        "    donor_data = donor_data[donor_data['Amount'] > 0]  # Exclude $0 donations\n",
        "\n",
        "    # Donation statistics\n",
        "    num_donations = donor_data.shape[0]\n",
        "    avg_donation = donor_data['Amount'].mean()\n",
        "    max_donation = donor_data['Amount'].max()\n",
        "\n",
        "    # Extract selected demographic features\n",
        "    feature_values = []\n",
        "    for feature in selected_features:\n",
        "        feature_values.append(donor_data[feature].mean() if feature in donor_data.columns else np.nan)\n",
        "\n",
        "    # Combine into feature vector\n",
        "    return [num_donations, avg_donation, max_donation] + feature_values\n",
        "\n",
        "# Train and evaluate the model\n",
        "# Train and evaluate the model\n",
        "# Train and evaluate the model\n",
        "def train_and_evaluate(X, y, donations_merged, training_donors, evaluation_donors, selected_features):\n",
        "\n",
        "    # Balance the dataset using random oversampling\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_res, y_res = ros.fit_resample(X, y)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_res = np.array(X_res)\n",
        "    y_res = np.array(y_res)\n",
        "\n",
        "    # Initialize Stratified K-Fold\n",
        "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "    accuracies, f1_scores, precision_scores, recall_scores = [], [], [], []\n",
        "\n",
        "    for train_idx, test_idx in skf.split(X_res, y_res):\n",
        "        X_train, X_test = X_res[train_idx], X_res[test_idx]\n",
        "        y_train, y_test = y_res[train_idx], y_res[test_idx]\n",
        "\n",
        "        # Train the model\n",
        "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        rf.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = rf.predict(X_test)\n",
        "\n",
        "        # Collect metrics for evaluation\n",
        "\n",
        "        f1_scores.append(f1_score(y_test, y_pred))\n",
        "        precision_scores.append(precision_score(y_test, y_pred))\n",
        "        recall_scores.append(recall_score(y_test, y_pred))\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\"F1 Score: {np.mean(f1_scores):.4f}\")\n",
        "    print(f\"Precision: {np.mean(precision_scores):.4f}\")\n",
        "    print(f\"Recall: {np.mean(recall_scores):.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "    # Make predictions on the evaluation set\n",
        "    # Make predictions on the evaluation set\n",
        "    evaluation_features = []\n",
        "    for donor in evaluation_donors:\n",
        "      feature_vector = gather_features(donor, donations_merged, selected_features)\n",
        "      evaluation_features.append(feature_vector)\n",
        "    # Predictions for next year (evaluation period)\n",
        "    y_pred = rf.predict(evaluation_features)\n",
        "\n",
        "\n",
        "    # Calculate the percentage of donors predicted to repeat\n",
        "    predicted_repeat_donors = np.sum(y_pred)\n",
        "    total_donors = len(y_pred)\n",
        "    predicted_repeat_percentage = (predicted_repeat_donors / total_donors) * 100\n",
        "    print(\"\\nPercentage of Donors Predicted to Repeat Again:\", predicted_repeat_percentage)\n",
        "\n",
        "    return rf\n",
        "\n",
        "# Main workflow\n",
        "def main():\n",
        "    # File paths\n",
        "    donations_file = 'DonationsC5LA.csv'\n",
        "    demographics_file = 'ACSSociodemographics.csv'\n",
        "    zipcode_file = 'Zipcode.csv'\n",
        "\n",
        "    # Load and preprocess data\n",
        "    donations_merged, demographics_df = load_and_merge_data(donations_file, demographics_file, zipcode_file)\n",
        "\n",
        "    # Define the model date\n",
        "    MODEL_DATE = '2022-01-01'\n",
        "\n",
        "    # Create labels\n",
        "    training_donors, evaluation_donors = create_labels(donations_merged, MODEL_DATE)\n",
        "\n",
        "    # Extract all demographic feature names (excluding ZCTA)\n",
        "    demographic_features = [\n",
        "        col for col in demographics_df.columns\n",
        "        if demographics_df[col].dtype.kind in 'bifc' and col != 'ZCTA'\n",
        "    ]\n",
        "\n",
        "    # Compute feature importance to select top 3 demographic features\n",
        "    all_training_features = []\n",
        "    all_training_labels = []\n",
        "\n",
        "    for donor in training_donors:\n",
        "        feature_vector = gather_features(donor, donations_merged, demographic_features)\n",
        "        label = 1 if donor in evaluation_donors else 0\n",
        "        all_training_features.append(feature_vector)\n",
        "        all_training_labels.append(label)\n",
        "\n",
        "    # Train a preliminary model to get feature importance\n",
        "    rf_preliminary = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_preliminary.fit(all_training_features, all_training_labels)\n",
        "    importances = rf_preliminary.feature_importances_\n",
        "\n",
        "    # Get the top 3 demographic features\n",
        "    all_features = ['num_donations', 'avg_donation', 'max_donation'] + demographic_features\n",
        "    importance_df = pd.DataFrame({'Feature': all_features, 'Importance': importances})\n",
        "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "    top_demographic_features = importance_df[importance_df['Feature'].isin(demographic_features)].head(3)['Feature'].tolist()\n",
        "    print(\"Top 3 Demographic Features:\", top_demographic_features)\n",
        "\n",
        "\n",
        "    # Final feature extraction with selected demographic features\n",
        "    final_training_features = []\n",
        "    final_training_labels = []\n",
        "    for donor in training_donors:\n",
        "        feature_vector = gather_features(donor, donations_merged, top_demographic_features)\n",
        "        label = 1 if donor in evaluation_donors else 0\n",
        "        final_training_features.append(feature_vector)\n",
        "        final_training_labels.append(label)\n",
        "\n",
        "    # Train and evaluate the final model\n",
        "    rf_model = train_and_evaluate(final_training_features, final_training_labels, donations_merged, training_donors, evaluation_donors, top_demographic_features)\n",
        "\n",
        "# Run the main workflow\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymAAEweQtob8",
        "outputId": "cf27b994-d5c7-4a2a-82a7-a3b8b63fbf79"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Demographic Features: ['HH Income', 'Poor', '$125-150k']\n",
            "Accuracy: 0.9812206572769953\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98       213\n",
            "           1       0.96      1.00      0.98       213\n",
            "\n",
            "    accuracy                           0.98       426\n",
            "   macro avg       0.98      0.98      0.98       426\n",
            "weighted avg       0.98      0.98      0.98       426\n",
            "\n",
            "F1 Score: 0.9622\n",
            "Precision: 0.9281\n",
            "Recall: 0.9991\n",
            "Confusion Matrix:\n",
            "[[205   8]\n",
            " [  0 213]]\n",
            "\n",
            "Percentage of Donors Predicted to Repeat Again: 68.29268292682927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Load and preprocess the data\n",
        "def load_and_merge_data(donations_file, demographics_file, zipcode_file):\n",
        "    # Load data\n",
        "    donations_df = pd.read_csv(donations_file)\n",
        "    demographics_df = pd.read_csv(demographics_file)\n",
        "    zipcode_df = pd.read_csv(zipcode_file)\n",
        "\n",
        "    # Convert date column to datetime\n",
        "    donations_df['Close Date'] = pd.to_datetime(donations_df['Close Date'])\n",
        "\n",
        "    # Rename columns for consistency\n",
        "    donations_df.rename(columns={'Billing Zip/Postal Code': 'Billing_Zipcode'}, inplace=True)\n",
        "    zipcode_df.rename(columns={'zip_code': 'Zip_Code', 'zcta': 'ZCTA'}, inplace=True)\n",
        "\n",
        "    # Ensure ZIP codes are strings\n",
        "    donations_df['Billing_Zipcode'] = donations_df['Billing_Zipcode'].astype(str)\n",
        "    zipcode_df['Zip_Code'] = zipcode_df['Zip_Code'].astype(str)\n",
        "\n",
        "    # Merge datasets\n",
        "    donations_merged = donations_df.merge(zipcode_df, left_on='Billing_Zipcode', right_on='Zip_Code', how='left')\n",
        "    donations_merged = donations_merged.merge(demographics_df, on='ZCTA', how='left')\n",
        "\n",
        "    return donations_merged, demographics_df\n",
        "\n",
        "# Create labels for donors\n",
        "def create_labels(donations_merged, model_date):\n",
        "    training_donors = donations_merged[donations_merged['Close Date'] < model_date]['Masked Account ID'].unique()\n",
        "    evaluation_donors = donations_merged[\n",
        "        (donations_merged['Close Date'] >= model_date) &\n",
        "        (donations_merged['Close Date'] < '2022-01-01')\n",
        "    ]['Masked Account ID'].unique()\n",
        "    return training_donors, evaluation_donors\n",
        "\n",
        "# Gather features for a donor\n",
        "def gather_features(donor_id, donations_merged, selected_features):\n",
        "    donor_data = donations_merged[donations_merged['Masked Account ID'] == donor_id]\n",
        "    donor_data = donor_data[donor_data['Amount'] > 0]  # Exclude $0 donations\n",
        "\n",
        "    # Donation statistics\n",
        "    num_donations = donor_data.shape[0]\n",
        "    avg_donation = donor_data['Amount'].mean()\n",
        "    max_donation = donor_data['Amount'].max()\n",
        "\n",
        "    # Extract selected demographic features\n",
        "    feature_values = []\n",
        "    for feature in selected_features:\n",
        "        feature_values.append(donor_data[feature].mean() if feature in donor_data.columns else np.nan)\n",
        "\n",
        "    # Combine into feature vector\n",
        "    return [num_donations, avg_donation, max_donation] + feature_values\n",
        "\n",
        "# Train and evaluate the model\n",
        "def train_and_evaluate(X, y):\n",
        "    # Balance the dataset using random oversampling\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_res, y_res = ros.fit_resample(X, y)\n",
        "\n",
        "    # Split into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions and evaluate\n",
        "    y_pred = rf.predict(X_test)\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "      # Calculate the percentage of donors predicted to repeat again\n",
        "    predicted_repeat_donors = np.sum(y_pred)\n",
        "    total_donors = len(y_pred)\n",
        "    predicted_repeat_percentage = (predicted_repeat_donors / total_donors) * 100\n",
        "    print(\"\\nPercentage of Donors Predicted to Repeat Again:\", predicted_repeat_percentage)\n",
        "\n",
        "\n",
        "    return rf\n",
        "\n",
        "# Main workflow\n",
        "def main():\n",
        "    # File paths\n",
        "    donations_file = 'DonationsC5LA.csv'\n",
        "    demographics_file = 'ACSSociodemographics.csv'\n",
        "    zipcode_file = 'Zipcode.csv'\n",
        "\n",
        "    # Load and preprocess data\n",
        "    donations_merged, demographics_df = load_and_merge_data(donations_file, demographics_file, zipcode_file)\n",
        "\n",
        "    # Define the model date\n",
        "    MODEL_DATE = '2021-01-01'\n",
        "\n",
        "    # Create labels\n",
        "    training_donors, evaluation_donors = create_labels(donations_merged, MODEL_DATE)\n",
        "\n",
        "    # Extract all demographic feature names (excluding ZCTA)\n",
        "    demographic_features = [\n",
        "        col for col in demographics_df.columns\n",
        "        if demographics_df[col].dtype.kind in 'bifc' and col != 'ZCTA'\n",
        "    ]\n",
        "\n",
        "    # Compute feature importance to select top 3 demographic features\n",
        "    all_training_features = []\n",
        "    all_training_labels = []\n",
        "\n",
        "    for donor in training_donors:\n",
        "        feature_vector = gather_features(donor, donations_merged, demographic_features)\n",
        "        label = 1 if donor in evaluation_donors else 0\n",
        "        all_training_features.append(feature_vector)\n",
        "        all_training_labels.append(label)\n",
        "\n",
        "    # Train a preliminary model to get feature importance\n",
        "    rf_preliminary = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_preliminary.fit(all_training_features, all_training_labels)\n",
        "    importances = rf_preliminary.feature_importances_\n",
        "\n",
        "    # Get the top 3 demographic features\n",
        "    all_features = ['num_donations', 'avg_donation', 'max_donation'] + demographic_features\n",
        "    importance_df = pd.DataFrame({'Feature': all_features, 'Importance': importances})\n",
        "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "    top_demographic_features = importance_df[importance_df['Feature'].isin(demographic_features)].head(3)['Feature'].tolist()\n",
        "    print(\"Top 3 Demographic Features:\", top_demographic_features)\n",
        "\n",
        "    # Final feature extraction with selected demographic features\n",
        "    final_training_features = []\n",
        "    final_training_labels = []\n",
        "    for donor in training_donors:\n",
        "        feature_vector = gather_features(donor, donations_merged, top_demographic_features)\n",
        "        label = 1 if donor in evaluation_donors else 0\n",
        "        final_training_features.append(feature_vector)\n",
        "        final_training_labels.append(label)\n",
        "\n",
        "    # Train and evaluate the final model\n",
        "    train_and_evaluate(final_training_features, final_training_labels)\n",
        "\n",
        "# Run the main workflow\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctxg87e2oP7y",
        "outputId": "68bcb5d5-4660-47db-84bc-43f5c6f48f8b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Demographic Features: ['Poor Family', 'HH Income', 'Minority']\n",
            "Accuracy: 0.9600997506234414\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.93      0.96       206\n",
            "           1       0.93      0.99      0.96       195\n",
            "\n",
            "    accuracy                           0.96       401\n",
            "   macro avg       0.96      0.96      0.96       401\n",
            "weighted avg       0.96      0.96      0.96       401\n",
            "\n",
            "Confusion Matrix:\n",
            "[[192  14]\n",
            " [  2 193]]\n",
            "\n",
            "Percentage of Donors Predicted to Repeat Again: 51.6209476309227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Load and preprocess the data\n",
        "def load_and_merge_data(donations_file, demographics_file, zipcode_file):\n",
        "    donations_df = pd.read_csv(donations_file)\n",
        "    demographics_df = pd.read_csv(demographics_file)\n",
        "    zipcode_df = pd.read_csv(zipcode_file)\n",
        "\n",
        "    donations_df['Close Date'] = pd.to_datetime(donations_df['Close Date'])\n",
        "    donations_df.rename(columns={'Billing Zip/Postal Code': 'Billing_Zipcode'}, inplace=True)\n",
        "    zipcode_df.rename(columns={'zip_code': 'Zip_Code', 'zcta': 'ZCTA'}, inplace=True)\n",
        "\n",
        "    donations_df['Billing_Zipcode'] = donations_df['Billing_Zipcode'].astype(str)\n",
        "    zipcode_df['Zip_Code'] = zipcode_df['Zip_Code'].astype(str)\n",
        "\n",
        "    donations_merged = donations_df.merge(zipcode_df, left_on='Billing_Zipcode', right_on='Zip_Code', how='left')\n",
        "    donations_merged = donations_merged.merge(demographics_df, on='ZCTA', how='left')\n",
        "\n",
        "    return donations_merged, demographics_df\n",
        "\n",
        "# Create labels for donors\n",
        "def create_labels(donations_merged, model_date):\n",
        "    model_date = pd.to_datetime(model_date)\n",
        "    training_donors = donations_merged[donations_merged['Close Date'] < model_date]['Masked Account ID'].unique()\n",
        "    evaluation_donors = donations_merged[\n",
        "        (donations_merged['Close Date'] >= model_date) &\n",
        "        (donations_merged['Close Date'] < f'{model_date.year + 1}-01-01')\n",
        "    ]['Masked Account ID'].unique()\n",
        "    return training_donors, evaluation_donors\n",
        "\n",
        "# Gather features for a donor\n",
        "def gather_features(donor_id, donations_merged, selected_features):\n",
        "    donor_data = donations_merged[donations_merged['Masked Account ID'] == donor_id]\n",
        "    donor_data = donor_data[donor_data['Amount'] > 0]  # Exclude $0 donations\n",
        "\n",
        "    # Donation statistics\n",
        "    num_donations = donor_data.shape[0]\n",
        "    avg_donation = donor_data['Amount'].mean()\n",
        "    max_donation = donor_data['Amount'].max()\n",
        "\n",
        "    # Extract selected demographic features\n",
        "    feature_values = []\n",
        "    for feature in selected_features:\n",
        "        feature_values.append(donor_data[feature].mean() if feature in donor_data.columns else np.nan)\n",
        "\n",
        "    # Combine into feature vector\n",
        "    return [num_donations, avg_donation, max_donation] + feature_values\n",
        "\n",
        "# Train and evaluate the model\n",
        "def train_and_evaluate(X, y, donations_merged, training_donors, evaluation_donors, selected_features):\n",
        "\n",
        "    # Balance the dataset using random oversampling\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_res, y_res = ros.fit_resample(X, y)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_res = np.array(X_res)\n",
        "    y_res = np.array(y_res)\n",
        "\n",
        "    # Initialize Stratified K-Fold\n",
        "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "    accuracies, f1_scores, precision_scores, recall_scores = [], [], [], []\n",
        "\n",
        "    # Training phase: Evaluate the training model using cross-validation\n",
        "    for train_idx, test_idx in skf.split(X_res, y_res):\n",
        "        X_train, X_test = X_res[train_idx], X_res[test_idx]\n",
        "        y_train, y_test = y_res[train_idx], y_res[test_idx]\n",
        "\n",
        "        # Train the model\n",
        "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        rf.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = rf.predict(X_test)\n",
        "\n",
        "        # Collect metrics for training evaluation\n",
        "        accuracies.append(accuracy_score(y_test, y_pred))\n",
        "        f1_scores.append(f1_score(y_test, y_pred))\n",
        "        precision_scores.append(precision_score(y_test, y_pred))\n",
        "        recall_scores.append(recall_score(y_test, y_pred))\n",
        "\n",
        "    # Print results for training run\n",
        "    print(\"\\nTraining Run Metrics:\")\n",
        "    print(f\"Accuracy: {np.mean(accuracies):.4f}\")\n",
        "    print(f\"F1 Score: {np.mean(f1_scores):.4f}\")\n",
        "    print(f\"Precision: {np.mean(precision_scores):.4f}\")\n",
        "    print(f\"Recall: {np.mean(recall_scores):.4f}\")\n",
        "\n",
        "    # Evaluation phase: Make predictions on the evaluation set (next year's data)\n",
        "    evaluation_features = []\n",
        "    for donor in evaluation_donors:\n",
        "        feature_vector = gather_features(donor, donations_merged, selected_features)\n",
        "        evaluation_features.append(feature_vector)\n",
        "\n",
        "    # Predictions for next year (evaluation period)\n",
        "    y_pred = rf.predict(evaluation_features)\n",
        "    print(\"\\nEvaluation Run Predictions (Next Year's Data):\", y_pred)\n",
        "\n",
        "    # Calculate the percentage of donors predicted to repeat\n",
        "    predicted_repeat_donors = np.sum(y_pred)\n",
        "    total_donors = len(y_pred)\n",
        "    predicted_repeat_percentage = (predicted_repeat_donors / total_donors) * 100\n",
        "    print(\"\\nPercentage of Donors Predicted to Repeat Again:\", predicted_repeat_percentage)\n",
        "\n",
        "    return rf\n",
        "\n",
        "# Main workflow\n",
        "def main():\n",
        "    # File paths\n",
        "    donations_file = 'DonationsC5LA.csv'\n",
        "    demographics_file = 'ACSSociodemographics.csv'\n",
        "    zipcode_file = 'Zipcode.csv'\n",
        "\n",
        "    # Load and preprocess data\n",
        "    donations_merged, demographics_df = load_and_merge_data(donations_file, demographics_file, zipcode_file)\n",
        "\n",
        "    # Define the model date\n",
        "    MODEL_DATE = '2021-01-01'\n",
        "\n",
        "    # Create labels\n",
        "    training_donors, evaluation_donors = create_labels(donations_merged, MODEL_DATE)\n",
        "\n",
        "    # Extract all demographic feature names (excluding ZCTA)\n",
        "    demographic_features = [\n",
        "        col for col in demographics_df.columns\n",
        "        if demographics_df[col].dtype.kind in 'bifc' and col != 'ZCTA'\n",
        "    ]\n",
        "\n",
        "    # Compute feature importance to select top 3 demographic features\n",
        "    all_training_features = []\n",
        "    all_training_labels = []\n",
        "\n",
        "    for donor in training_donors:\n",
        "        feature_vector = gather_features(donor, donations_merged, demographic_features)\n",
        "        label = 1 if donor in evaluation_donors else 0\n",
        "        all_training_features.append(feature_vector)\n",
        "        all_training_labels.append(label)\n",
        "\n",
        "    # Train a preliminary model to get feature importance\n",
        "    rf_preliminary = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_preliminary.fit(all_training_features, all_training_labels)\n",
        "    importances = rf_preliminary.feature_importances_\n",
        "\n",
        "    # Get the top 3 demographic features\n",
        "    all_features = ['num_donations', 'avg_donation', 'max_donation'] + demographic_features\n",
        "    importance_df = pd.DataFrame({'Feature': all_features, 'Importance': importances})\n",
        "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "    top_demographic_features = importance_df[importance_df['Feature'].isin(demographic_features)].head(3)['Feature'].tolist()\n",
        "    print(\"Top 3 Demographic Features:\", top_demographic_features)\n",
        "\n",
        "    # Final feature extraction with selected demographic features\n",
        "    final_training_features = []\n",
        "    final_training_labels = []\n",
        "    for donor in training_donors:\n",
        "        feature_vector = gather_features(donor, donations_merged, top_demographic_features)\n",
        "        label = 1 if donor in evaluation_donors else 0\n",
        "        final_training_features.append(feature_vector)\n",
        "        final_training_labels.append(label)\n",
        "\n",
        "    # Train and evaluate the final model\n",
        "    rf_model = train_and_evaluate(final_training_features, final_training_labels, donations_merged, training_donors, evaluation_donors, top_demographic_features)\n",
        "\n",
        "# Run the main workflow\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gteK7Qlh_Hae",
        "outputId": "0a483f2a-ec5b-4315-a85c-22d43531b8ee"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Demographic Features: ['Poor Family', 'HH Income', 'Minority']\n",
            "\n",
            "Training Run Metrics:\n",
            "Accuracy: 0.9621\n",
            "F1 Score: 0.9635\n",
            "Precision: 0.9295\n",
            "Recall: 1.0000\n",
            "\n",
            "Evaluation Run Predictions (Next Year's Data): [1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1\n",
            " 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0\n",
            " 0 1 0 0 0 0 0 0]\n",
            "\n",
            "Percentage of Donors Predicted to Repeat Again: 65.21739130434783\n"
          ]
        }
      ]
    }
  ]
}